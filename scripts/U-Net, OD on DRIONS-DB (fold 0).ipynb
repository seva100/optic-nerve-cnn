{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of modified U-Net for Optic Disc on DRIONS-DB database, 256 px images (cross-validation fold #0).\n",
    "\n",
    "You can either train your model or upload a pre-trained one from:\n",
    "*../models_weights/05.03,02:40,U-Net light, on DRIONS-DB 256 px fold 0, SGD, high augm, CLAHE, log_dice loss/last_checkpoint.hdf5*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "#import warnings\n",
    "#warnings.simplefilter('ignore')\n",
    "import scipy as sp\n",
    "import scipy.ndimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import skimage\n",
    "import skimage.exposure\n",
    "import mahotas as mh\n",
    "from sklearn.model_selection import KFold\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import h5py\n",
    "from tqdm import tqdm_notebook\n",
    "from IPython.display import display\n",
    "from dual_IDG import DualImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Activation, Flatten, \\\n",
    "    Conv2D, MaxPooling2D, ZeroPadding2D, Input, Embedding, \\\n",
    "    Lambda, UpSampling2D, Cropping2D, Concatenate\n",
    "BatchNormalization = tf.keras.layers.BatchNormalization\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "Adam = tf.keras.optimizers.Adam\n",
    "SGD = tf.keras.optimizers.SGD\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, CSVLogger\n",
    "ImageDataGenerator = tf.keras.preprocessing.image.ImageDataGenerator\n",
    "import tensorflow.python.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TensorFlow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_IOU_gpu(X, Y):\n",
    "    \"\"\"Computes mean Intersection-over-Union (IOU) for two arrays of binary images.\n",
    "    Assuming X and Y are of shape (n_images, w, h).\"\"\"\n",
    "    \n",
    "    #X_fl = K.clip(K.batch_flatten(X), K.epsilon(), 1.)\n",
    "    #Y_fl = K.clip(K.batch_flatten(Y), K.epsilon(), 1.)\n",
    "    X_fl = K.clip(K.batch_flatten(X), 0., 1.)\n",
    "    Y_fl = K.clip(K.batch_flatten(Y), 0., 1.)\n",
    "    X_fl = K.cast(K.greater(X_fl, 0.5), 'float32')\n",
    "    Y_fl = K.cast(K.greater(Y_fl, 0.5), 'float32')\n",
    "\n",
    "    intersection = K.sum(X_fl * Y_fl, axis=1)\n",
    "    union = K.sum(K.maximum(X_fl, Y_fl), axis=1)\n",
    "    # if union == 0, it follows that intersection == 0 => score should be 0.\n",
    "    union = K.switch(K.equal(union, 0), K.ones_like(union), union)\n",
    "    return K.mean(intersection / K.cast(union, 'float32'))\n",
    "\n",
    "\n",
    "def mean_IOU_gpu_loss(X, Y):\n",
    "    return -mean_IOU_gpu(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(y_true, y_pred):\n",
    "    # Workaround for shape bug. For some reason y_true shape was not being set correctly\n",
    "    #y_true.set_shape(y_pred.get_shape())\n",
    "\n",
    "    # Without K.clip, K.sum() behaves differently when compared to np.count_nonzero()\n",
    "    #y_true_f = K.clip(K.batch_flatten(y_true), K.epsilon(), 1.)\n",
    "    #y_pred_f = K.clip(K.batch_flatten(y_pred), K.epsilon(), 1.)\n",
    "    y_true_f = K.clip(K.batch_flatten(y_true), 0., 1.)\n",
    "    y_pred_f = K.clip(K.batch_flatten(y_pred), 0., 1.)\n",
    "    #y_pred_f = K.greater(y_pred_f, 0.5)\n",
    "\n",
    "    intersection = 2 * K.sum(y_true_f * y_pred_f, axis=1)\n",
    "    union = K.sum(y_true_f * y_true_f, axis=1) + K.sum(y_pred_f * y_pred_f, axis=1)\n",
    "    return K.mean(intersection / union)\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return -dice(y_true, y_pred)\n",
    "\n",
    "\n",
    "def log_dice_loss(y_true, y_pred):\n",
    "    return -K.log(dice(y_true, y_pred))\n",
    "\n",
    "\n",
    "def dice_metric(y_true, y_pred):\n",
    "    \"\"\"An exact Dice score for binary tensors.\"\"\"\n",
    "    y_true_f = K.cast(K.greater(y_true, 0.5), 'float32')\n",
    "    y_pred_f = K.cast(K.greater(y_pred, 0.5), 'float32')\n",
    "    return dice(y_true_f, y_pred_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_to_th_encoding(X):\n",
    "    return np.rollaxis(X, 3, 1)\n",
    "\n",
    "\n",
    "def th_to_tf_encoding(X):\n",
    "    return np.rollaxis(X, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h5f = h5py.File(os.path.join(os.path.dirname(os.getcwd()), 'data', 'hdf5_datasets', 'all_data.hdf5'), 'r')\n",
    "h5f = h5py.File(os.path.join(os.path.dirname(os.getcwd()), 'data', 'hdf5_datasets', 'DRIONS_DB.hdf5'), 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net architecture\n",
    "\n",
    "<img src=\"../pics/u_net_arch.png\" width=80%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet_light(img_rows=256, img_cols=256):\n",
    "    inputs = Input((3, img_rows, img_cols))\n",
    "    conv1 = Conv2D(32, kernel_size=3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Dropout(0.3)(conv1)\n",
    "    conv1 = Conv2D(32, kernel_size=3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Dropout(0.3)(conv2)\n",
    "    conv2 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Dropout(0.3)(conv3)\n",
    "    conv3 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = Dropout(0.3)(conv4)\n",
    "    conv4 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = Dropout(0.3)(conv5)\n",
    "    conv5 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = Concatenate(axis=1)([UpSampling2D(size=(2, 2))(conv5), conv4])\n",
    "    conv6 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(up6)\n",
    "    conv6 = Dropout(0.3)(conv6)\n",
    "    conv6 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = Concatenate(axis=1)([UpSampling2D(size=(2, 2))(conv6), conv3])\n",
    "    conv7 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(up7)\n",
    "    conv7 = Dropout(0.3)(conv7)\n",
    "    conv7 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = Concatenate(axis=1)([UpSampling2D(size=(2, 2))(conv7), conv2])\n",
    "    conv8 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(up8)\n",
    "    conv8 = Dropout(0.3)(conv8)\n",
    "    conv8 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = Concatenate(axis=1)([UpSampling2D(size=(2, 2))(conv8), conv1])\n",
    "    conv9 = Conv2D(32, kernel_size=3, activation='relu', padding='same')(up9)\n",
    "    conv9 = Dropout(0.3)(conv9)\n",
    "    conv9 = Conv2D(32, kernel_size=3, activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, kernel_size=1, activation='sigmoid', padding='same')(conv9)\n",
    "    #conv10 = Flatten()(conv10)\n",
    "\n",
    "    model = Model(input=inputs, output=conv10)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = get_unet_light(img_rows=256, img_cols=256)\n",
    "model.compile(optimizer=SGD(lr=3e-4, momentum=0.95),\n",
    "              loss=log_dice_loss,\n",
    "              metrics=[mean_IOU_gpu, dice_metric])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DRIONS-DB\n",
    "\n",
    "Accessing data, preparing train/validation sets division:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = h5f['DRIONS-DB/256 px/images']\n",
    "Y = h5f['DRIONS-DB/256 px/disc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx_cv, test_idx_cv = [], []\n",
    "\n",
    "for _train_idx, _test_idx in KFold(n_splits=5, random_state=1).split(X):\n",
    "    print(_train_idx, _test_idx)\n",
    "    train_idx_cv.append(_train_idx)\n",
    "    test_idx_cv.append(_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_idx = h5f['RIM-ONE v3/train_idx_driu']\n",
    "#test_idx = h5f['RIM-ONE v3/test_idx_driu']\n",
    "\n",
    "train_idx = train_idx_cv[0]\n",
    "test_idx = test_idx_cv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X), len(train_idx), len(test_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator of augmented data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idg = DualImageDataGenerator(#rescale=1/255.0,\n",
    "                                   #samplewise_center=True, samplewise_std_normalization=True,\n",
    "                                   horizontal_flip=True, vertical_flip=True,\n",
    "                                   rotation_range=50, width_shift_range=0.15, height_shift_range=0.15,\n",
    "                                   zoom_range=(0.7, 1.3),\n",
    "                                   fill_mode='constant', cval=0.0)\n",
    "test_idg = DualImageDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing function and data generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch_X, batch_y, train_or_test='train'):\n",
    "    batch_X = batch_X / 255.0\n",
    "    batch_y = batch_y / 255.0\n",
    "    if train_or_test == 'train':\n",
    "        batch_X, batch_y = next(train_idg.flow(batch_X, batch_y, batch_size=len(batch_X), shuffle=False))\n",
    "    elif train_or_test == 'test':\n",
    "        batch_X, batch_y = next(test_idg.flow(batch_X, batch_y, batch_size=len(batch_X), shuffle=False))\n",
    "    batch_X = th_to_tf_encoding(batch_X)\n",
    "    batch_X = [skimage.exposure.equalize_adapthist(batch_X[i]) \n",
    "               for i in range(len(batch_X))]\n",
    "    batch_X = np.array(batch_X)\n",
    "    batch_X = tf_to_th_encoding(batch_X)\n",
    "    return batch_X, batch_y\n",
    "\n",
    "\n",
    "def data_generator(X, y, train_or_test='train', batch_size=3, return_orig=False, stationary=False):\n",
    "    while True:\n",
    "        if train_or_test == 'train':\n",
    "            idx = np.random.choice(train_idx, size=batch_size)\n",
    "        elif train_or_test == 'test':\n",
    "            if stationary:\n",
    "                idx = test_idx[:batch_size]\n",
    "            else:\n",
    "                idx = np.random.choice(test_idx, size=batch_size)\n",
    "        batch_X = [X[i] for i in idx]\n",
    "        batch_X = np.array(batch_X).copy()\n",
    "        batch_y = [y[i] for i in idx]\n",
    "        batch_y = np.array(batch_y).copy()\n",
    "        batch_X = tf_to_th_encoding(batch_X)\n",
    "        batch_y = tf_to_th_encoding(batch_y)\n",
    "        if return_orig:\n",
    "            batch_X_orig, batch_Y_orig = batch_X.copy(), batch_y.copy()\n",
    "        \n",
    "        batch_X, batch_y = preprocess(batch_X, batch_y, train_or_test)\n",
    "        \n",
    "        if not return_orig:\n",
    "            yield batch_X, batch_y\n",
    "        else:\n",
    "            yield batch_X, batch_y, batch_X_orig, batch_Y_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the data generator and generator for augmented data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen = data_generator(X, Y, 'train', batch_size=1)\n",
    "batch = next(gen)\n",
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.imshow(np.rollaxis(batch[0][0], 0, 3))\n",
    "#plt.colorbar(mappable=fig)\n",
    "plt.show()\n",
    "plt.imshow(batch[1][0][0], cmap=plt.cm.Greys_r); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_name = \"U-Net light, on DRIONS-DB 256 px fold 0, SGD, high augm, CLAHE, log_dice loss\"\n",
    "weights_folder = os.path.join(os.path.dirname(os.getcwd()), 'models_weights',\n",
    "                              '{},{}'.format(datetime.now().strftime('%d.%m,%H:%M'), arch_name))\n",
    "print(weights_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder(folder_name):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    return folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, Y_valid = next(data_generator(X, Y, train_or_test='test', batch_size=100, stationary=True))\n",
    "plt.imshow(np.rollaxis(X_valid[0], 0, 3)); plt.show()\n",
    "print(X_valid.shape, Y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "If a pretrained model needs to be used, first run \"Loading model\" section below and then go the \"Comprehensive visual check\", skipping this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(data_generator(X, Y, train_or_test='train', batch_size=1), \n",
    "                              steps_per_epoch=99,\n",
    "                              max_queue_size=1,\n",
    "                              \n",
    "                              validation_data=(X_valid, Y_valid),\n",
    "                              #validation_data=data_generator(X, Y, train_or_test='test', batch_size=1),\n",
    "                              #nb_val_samples=100,\n",
    "                              \n",
    "                              epochs=500, verbose=1,\n",
    "                              \n",
    "                              callbacks=[CSVLogger(os.path.join(folder(weights_folder), 'training_log.csv')),\n",
    "                                         #ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.5, verbose=1, patience=40),\n",
    "                                         ModelCheckpoint(os.path.join(folder(weights_folder),\n",
    "                                               #'weights.ep-{epoch:02d}-val_mean_IOU-{val_mean_IOU_gpu:.2f}_val_loss_{val_loss:.2f}.hdf5',\n",
    "                                               'last_checkpoint.hdf5'),\n",
    "                                               monitor='val_loss', mode='min', save_best_only=True, \n",
    "                                               save_weights_only=False, verbose=0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_iou, pred_dice = [], []\n",
    "\n",
    "for i, img_no in enumerate(test_idx):\n",
    "    print('image #{}'.format(img_no))\n",
    "    img = X[img_no]\n",
    "    batch_X = X_valid[i:i + 1]\n",
    "    batch_y = Y_valid[i:i + 1]\n",
    "    \n",
    "    pred = (model.predict(batch_X)[0, 0] > 0.5).astype(np.float64)\n",
    "    #corr = Y[img_no][..., 0]\n",
    "    corr = th_to_tf_encoding(batch_y)[0, ..., 0]\n",
    "    \n",
    "    # mean filtering:\n",
    "    #pred = mh.mean_filter(pred, Bc=mh.disk(10)) > 0.5\n",
    "    \n",
    "    fig = plt.figure(figsize=(9, 4))\n",
    "    ax = fig.add_subplot(1, 3, 1)\n",
    "    ax.imshow(pred, cmap=plt.cm.Greys_r)\n",
    "    ax.set_title('Predicted')\n",
    "    ax = fig.add_subplot(1, 3, 2)\n",
    "    ax.imshow(corr, cmap=plt.cm.Greys_r)\n",
    "    ax.set_title('Correct')\n",
    "    ax = fig.add_subplot(1, 3, 3)\n",
    "    #ax.imshow(img)\n",
    "    ax.imshow(th_to_tf_encoding(batch_X)[0])\n",
    "    ax.set_title('Image')\n",
    "    plt.show()\n",
    "    \n",
    "    cur_iou = K.eval(mean_IOU_gpu(pred[None, None, ...], corr[None, None, ...]))\n",
    "    cur_dice = K.eval(dice(pred[None, None, ...], corr[None, None, ...]))\n",
    "    print('IOU: {}\\nDice: {}'.format(cur_iou, cur_dice))\n",
    "    pred_iou.append(cur_iou)\n",
    "    pred_dice.append(cur_dice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acquiring scores for the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(pred_iou))\n",
    "print(np.mean(pred_dice))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the best and the worst cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img_pred_corr(i, file_suffix):    # i is index of image in test_idx\n",
    "    img_no = test_idx[i]\n",
    "    batch_X = X[img_no:img_no + 1]\n",
    "    batch_X = tf_to_th_encoding(batch_X)\n",
    "    batch_y = Y[img_no:img_no + 1]\n",
    "    batch_y = tf_to_th_encoding(batch_y)\n",
    "    batch_X, batch_y = preprocess(batch_X, batch_y, 'test')\n",
    "    \n",
    "    pred = model.predict(batch_X)[0, 0] > 0.5\n",
    "    #corr = Y[img_no][..., 0]\n",
    "    corr = th_to_tf_encoding(batch_y)[0, ..., 0]\n",
    "    \n",
    "    fig = plt.figure(figsize=(9, 4))\n",
    "    ax = fig.add_subplot(1, 3, 1)\n",
    "    ax.imshow(pred, cmap=plt.cm.Greys_r)\n",
    "    ax.set_title('Predicted')\n",
    "    ax = fig.add_subplot(1, 3, 2)\n",
    "    ax.imshow(corr, cmap=plt.cm.Greys_r)\n",
    "    ax.set_title('Correct')\n",
    "    ax = fig.add_subplot(1, 3, 3)\n",
    "    #ax.imshow(img)\n",
    "    ax.imshow(X[img_no])\n",
    "    ax.set_title('Image')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.imsave('drions_db_fold_0_{}_case_image.png'.format(file_suffix), X[img_no])\n",
    "    plt.imsave('drions_db_fold_0_{}_case_pred.png'.format(file_suffix), pred, cmap=plt.cm.Greys_r)\n",
    "    plt.imsave('drions_db_fold_0_{}_case_corr.png'.format(file_suffix), corr, cmap=plt.cm.Greys_r)\n",
    "\n",
    "\n",
    "best_idx = np.argmax(pred_iou)\n",
    "worst_idx = np.argmin(pred_iou)\n",
    "show_img_pred_corr(best_idx, 'best')\n",
    "print('IOU: {} (best)'.format(pred_iou[best_idx]))\n",
    "show_img_pred_corr(worst_idx, 'worst')\n",
    "print('IOU: {} (worst)'.format(pred_iou[worst_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_model = True   # lock\n",
    "if not load_model:\n",
    "    print('load_model == False')\n",
    "else:\n",
    "    # specify file:\n",
    "    #model_path = '../models_weights/01.11,22:38,U-Net on DRIONS-DB 256 px, Adam, augm, log_dice loss/' \\\n",
    "    #    'weights.ep-20-val_mean_IOU-0.81_val_loss_0.08.hdf5'\n",
    "    \n",
    "    # or get the most recently modified file in a folder:\n",
    "    model_folder = os.path.join(os.path.dirname(os.getcwd()), 'models_weights', '05.03,02_40,U-Net light, on DRIONS-DB 256 px fold 0, SGD, high augm, CLAHE, log_dice loss')\n",
    "    \n",
    "    model_path = max(glob.glob(os.path.join(model_folder, '*.hdf5')), key=os.path.getctime)\n",
    "    if load_model and not os.path.exists(model_path):\n",
    "        raise Exception('`model_path` does not exist')\n",
    "    print('Loading weights from', model_path)\n",
    "\n",
    "    if load_model:\n",
    "        #with open(model_path + ' arch.json') as arch_file:\n",
    "        #    json_string = arch_file.read()\n",
    "        #new_model = model_from_json(json_string)\n",
    "        model.load_weights(model_path)\n",
    "    \n",
    "    # Reading log statistics\n",
    "    import pandas as pd\n",
    "    \n",
    "    log_path = os.path.join(model_folder, 'training_log.csv')\n",
    "    if os.path.exists(log_path):\n",
    "        log = pd.read_csv(log_path)\n",
    "        if log['epoch'].dtype != 'int64':\n",
    "            log = log.loc[log.epoch != 'epoch']\n",
    "        print('\\nmax val mean IOU: {}, at row:'.format(log['val_mean_IOU_gpu'].max()))\n",
    "        print(log.loc[log['val_mean_IOU_gpu'].idxmax()])\n",
    "        if 'val_dice_metric' in log.columns:\n",
    "            print('\\n' + 'max val dice_metric: {}, at row:'.format(log['val_dice_metric'].max()))\n",
    "            print(log.loc[log['val_dice_metric'].idxmax()])\n",
    "        if 'val_dice' in log.columns:\n",
    "            print('\\n' + 'max val dice: {}, at row:'.format(log['val_dice'].max()))\n",
    "            print(log.loc[log['val_dice'].idxmax()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}